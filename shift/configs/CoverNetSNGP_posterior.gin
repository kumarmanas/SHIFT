# Default Configuration for SNGP CoverNet
NuscenesDataset.data_dir = '/mnt/share/datasets/nuscenes/'
NuscenesDataset.cache_dir = '/mnt/share/datasets/nuscenes/cache2'
NuscenesDataset.data_version = 'v1.0-trainval'

train/NuscenesDataset.split = 'train'
val/NuscenesDataset.split = 'train_val'
test/NuscenesDataset.split = 'val'

NuscenesDataset.y_all_valid=True
Trainer.multi_label=True

Trainer.model_factory = @CovernetSNGP
Trainer.batch_size=32
Trainer.epochs=200
Trainer.lr = 2.4e-4
Trainer.spec_norm_bound = 8.21875
Trainer.eps_set=4

Trainer.mixed_precision = False

Trainer.use_spec_norm = True # if feature extractor is spectral normalized or not
#Trainer.spec_norm_iteration # number of power iterations
#Trainer.spec_norm_bound # upper bound of spectral norm

#Trainer.use_gp_layer = True # if GP is used as last layer or not
Trainer.gp_num_inducing=1024 # number of random features
Trainer.gp_kernel_scale = 22.016 # length scale of RBF kernel
Trainer.gp_l2_regularizer=1.0 # weight of L2 regularization on extractor output weights
#Trainer.gp_cov_ridge_factor # covariance computation
#Trainer.gp_cov_discount_factor # covariance computation
#Trainer.gp_mean_field_factor # temperature in mean field

Trainer.early_stop_delay = 0
Trainer.early_stop_patience = 15

paramSearch.space = {
				"gp_posterior_temp": ("logfloat", 0.00001, 0.1),
				"extractor_posterior_temp": ("logfloat", 1.0, 10000.)
            		}  
paramSearch.numTrials = 16
